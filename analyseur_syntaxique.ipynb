{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsingError(Exception):\n",
    "    \"\"\"Exception personnalisée pour les erreurs de parsing.\"\"\"\n",
    "    def __init__(self, message, line_number=None, position=None):\n",
    "        self.message = message\n",
    "        self.line_number = line_number\n",
    "        self.position = position\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectif** : \n",
    "Créer une exception spécifique pour les erreurs de parsing, qui inclut un message d'erreur et une position dans le code pour faciliter le débogage.\n",
    "\n",
    "**Explications** :\n",
    "Le constructeur prend un message et une position (facultative) pour indiquer où l'erreur s'est produite.\n",
    "Cette exception sera utilisée plus tard pour capturer et signaler les erreurs lors de l'analyse du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe principale du parser\n",
    "class MTddVParser:\n",
    "    def __init__(self, code):\n",
    "        \"\"\"Initialisation du parser avec le code à analyser.\"\"\"\n",
    "        self.code = code\n",
    "        self.tokens = self.tokenize(code)\n",
    "        self.current_token_index = 0\n",
    "        self.errors = []\n",
    "        self.boucle_stack = []\n",
    "\n",
    "    def tokenize(self, code):\n",
    "        \"\"\"Tokeniser le code d'entrée.\"\"\"\n",
    "        lines = code.splitlines()\n",
    "        tokens = []\n",
    "        for line_number, line in enumerate(lines, start=1):\n",
    "            line_tokens = re.findall(r'\\w+|[{}#()]|fin|%', line)\n",
    "            for token in line_tokens:\n",
    "                tokens.append({\"token\": token, \"line_number\": line_number})\n",
    "        return tokens\n",
    "\n",
    "    def current_token(self):\n",
    "        \"\"\"Retourner le token actuel.\"\"\"\n",
    "        if self.current_token_index < len(self.tokens):\n",
    "            return self.tokens[self.current_token_index][\"token\"]\n",
    "        return None\n",
    "\n",
    "    def current_line_number(self):\n",
    "        \"\"\"Retourner le numéro de ligne du token actuel.\"\"\"\n",
    "        if self.current_token_index < len(self.tokens):\n",
    "            return self.tokens[self.current_token_index][\"line_number\"]\n",
    "        return None\n",
    "\n",
    "    def advance(self):\n",
    "        \"\"\"Avancer au token suivant.\"\"\"\n",
    "        self.current_token_index += 1\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"Effectuer le parsing et construire la structure d'instructions.\"\"\"\n",
    "        structure = []\n",
    "        while self.current_token():\n",
    "            try:\n",
    "                instruction = self.parse_instruction()\n",
    "                if instruction:\n",
    "                    structure.append(instruction)\n",
    "            except ParsingError as e:\n",
    "                self.errors.append({\n",
    "                    \"error\": e.message,\n",
    "                    \"line_number\": e.line_number,\n",
    "                    \"position\": self.current_token_index\n",
    "                })\n",
    "                self.advance()\n",
    "\n",
    "        if self.boucle_stack:\n",
    "            self.errors.append({\n",
    "                \"error\": \"Unclosed 'boucle' block(s) detected.\",\n",
    "                \"line_number\": self.current_line_number(),\n",
    "                \"position\": self.current_token_index\n",
    "            })\n",
    "\n",
    "        if self.tokens and self.tokens[-1][\"token\"] != \"#\":\n",
    "            self.errors.append({\n",
    "                \"error\": \"Missing '#' at the end of the program.\",\n",
    "                \"line_number\": self.tokens[-1][\"line_number\"],\n",
    "                \"position\": len(self.tokens) - 1\n",
    "            })\n",
    "\n",
    "        return structure\n",
    "\n",
    "    def parse_instruction(self):\n",
    "        \"\"\"Analyser une instruction individuelle.\"\"\"\n",
    "        token = self.current_token()\n",
    "        if token in [\"I\", \"P\", \"G\", \"D\", \"0\", \"1\"]:\n",
    "            line_number = self.current_line_number()\n",
    "            self.advance()\n",
    "            return {\"type\": \"instruction\", \"value\": token, \"line_number\": line_number}\n",
    "        elif token == \"%\":\n",
    "            self.advance()\n",
    "            return {\"type\": \"comment\"}\n",
    "        elif token == \"#\":\n",
    "            self.advance()\n",
    "            if self.current_token():\n",
    "                self.errors.append({\n",
    "                    \"error\": \"'#' must be the last instruction in the program.\",\n",
    "                    \"line_number\": self.current_line_number(),\n",
    "                    \"position\": self.current_token_index\n",
    "                })\n",
    "            return {\"type\": \"end_marker\", \"value\": \"#\"}\n",
    "        elif token == \"si\":\n",
    "            line_number = self.current_line_number()\n",
    "            self.advance()\n",
    "            condition = self.parse_condition()\n",
    "            inner_structure = []\n",
    "            while self.current_token() != \"}\":\n",
    "                if self.current_token() is None:\n",
    "                    raise ParsingError(\"Missing closing '}' for 'si' block\", line_number)\n",
    "                inner_structure.append(self.parse_instruction())\n",
    "            self.advance()\n",
    "            return {\"type\": \"si\", \"condition\": condition, \"content\": inner_structure, \"line_number\": line_number}\n",
    "        elif token == \"boucle\":\n",
    "            line_number = self.current_line_number()\n",
    "            self.boucle_stack.append(\"boucle\")\n",
    "            self.advance()\n",
    "            inner_structure = []\n",
    "            while self.current_token() != \"}\":\n",
    "                if self.current_token() is None:\n",
    "                    raise ParsingError(\"Missing closing '}' for 'boucle' block\", line_number)\n",
    "                inner_structure.append(self.parse_instruction())\n",
    "            self.boucle_stack.pop()\n",
    "            self.advance()\n",
    "            return {\"type\": \"boucle\", \"content\": inner_structure, \"line_number\": line_number}\n",
    "        elif token == \"fin\":\n",
    "            line_number = self.current_line_number()\n",
    "            if not self.boucle_stack:\n",
    "                raise ParsingError(\"'fin' outside of any 'boucle' block\", line_number)\n",
    "            self.advance()\n",
    "            return {\"type\": \"fin\", \"line_number\": line_number}\n",
    "        else:\n",
    "            line_number = self.current_line_number()\n",
    "            raise ParsingError(f\"Unknown instruction '{token}'\", line_number)\n",
    "\n",
    "    def parse_condition(self):\n",
    "        \"\"\"Analyser la condition dans une instruction 'si'.\"\"\"\n",
    "        if self.current_token() == \"(\":\n",
    "            self.advance()\n",
    "            condition = self.current_token()\n",
    "            self.advance()\n",
    "            if self.current_token() == \")\":\n",
    "                self.advance()\n",
    "                return condition\n",
    "            else:\n",
    "                raise ParsingError(\"Expected ')' after condition in 'si'\", self.current_line_number())\n",
    "        raise ParsingError(\"Expected '(' after 'si'\", self.current_line_number())\n",
    "\n",
    "def generate_dot(structure, output_dot_path):\n",
    "    \"\"\"Génère un fichier DOT à partir de la structure d'instructions.\"\"\"\n",
    "    with open(output_dot_path, \"w\", encoding=\"utf-8\") as dot_file:\n",
    "        dot_file.write(\"digraph {\\n\")\n",
    "        dot_file.write(\"  rankdir=TB;\\n\")\n",
    "        for node_id, node in enumerate(structure):\n",
    "            label = f\"{node['type']}: {node.get('value', node.get('condition', ''))}\"\n",
    "            dot_file.write(f\"  {node_id} [label=\\\"{label}\\\"];\\n\")\n",
    "            if \"content\" in node:\n",
    "                for next_id in range(node_id + 1, node_id + 1 + len(node[\"content\"])):\n",
    "                    dot_file.write(f\"  {node_id} -> {next_id} [label=\\\"\\\"];\\n\")\n",
    "        dot_file.write(\"}\\n\")\n",
    "\n",
    "def generate_png_from_dot(dot_path, png_path):\n",
    "    \"\"\"Génère une image PNG à partir d'un fichier DOT.\"\"\"\n",
    "    try:\n",
    "        subprocess.run([\"dot\", \"-Tpng\", dot_path, \"-o\", png_path], check=True)\n",
    "        print(f\"Image PNG générée : {png_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Erreur lors de la génération de l'image PNG : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constructeur __init__ :\n",
    "\n",
    "**Objectif** : Initialiser l'instance du parser avec le code source à analyser.\n",
    "**Détails** :\n",
    "self.code : Le code source qui sera analysé.\n",
    "self.tokens : Liste des tokens générée en découpant le code par la méthode tokenize.\n",
    "self.current_token_index : Position actuelle dans la liste des tokens.\n",
    "self.errors : Liste qui contiendra les erreurs rencontrées durant l'analyse.\n",
    "self.boucle_stack : Pile utilisée pour suivre les blocs boucle imbriqués et s'assurer qu'ils sont correctement fermés.\n",
    "\n",
    "\n",
    "#### Méthode tokenize :\n",
    "\n",
    "**Objectif** : Récupérer le token actuel à analyser.\n",
    "**Détails** :\n",
    "Si l'index actuel est inférieur à la taille de la liste de tokens, retourne le token à cette position.\n",
    "Sinon, retourne None pour indiquer la fin des tokens.\n",
    "\n",
    "\n",
    "#### Méthode advance :\n",
    "\n",
    "**Objectif** : Avancer à l'élément suivant dans la liste des tokens.\n",
    "**Détails** :\n",
    "Augmente simplement l'index de current_token_index pour passer au token suivant.\n",
    "\n",
    "\n",
    "#### Méthode parse :\n",
    "\n",
    "**Objectif** : Analyser tout le code et produire la structure d'instructions, tout en collectant les erreurs.\n",
    "**Détails** :\n",
    "structure : Liste pour stocker les instructions valides extraites du code.\n",
    "Pour chaque token, parse_instruction() est appelée pour analyser les instructions.\n",
    "Si une exception ParsingError est levée, l'erreur est ajoutée à la liste errors et l'analyse continue avec le token suivant.\n",
    "Si des blocs boucle ne sont pas fermés, ou si le programme ne se termine pas par un #, des erreurs sont ajoutées.\n",
    "\n",
    "\n",
    "#### Méthode parse_instruction :\n",
    "\n",
    "**Objectif** : Analyser une instruction à partir du token actuel et renvoyer la structure de cette instruction.\n",
    "**Détails** : Selon le token, plusieurs blocs de code différents sont activés pour analyser des instructions spécifiques comme :\n",
    "Instructions de base (I, P, G, D, 0, 1) : Retourne une instruction de type \"instruction\".\n",
    "Commentaires (%) : Ignore le commentaire et le marque comme tel.\n",
    "Bloc conditionnel (si) : Analyse une instruction conditionnelle avec une condition entre parenthèses.\n",
    "Bloc de boucle (boucle) : Gère les boucles imbriquées et s'assure qu'elles sont correctement fermées.\n",
    "Fin de boucle (fin) : S'assure que fin apparaît bien dans un bloc boucle.\n",
    "\n",
    "### Méthode parse_condition :\n",
    "\n",
    "**Objectif** : Analyser la condition à l'intérieur d'un bloc si (si condition).\n",
    "**Détails** :\n",
    "Si la condition commence par ( et se termine par ), elle est extraite et renvoyée. Si la parenthèse fermante est manquante, une erreur est ajoutée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image PNG générée : ./results/parsed_structure.png\n"
     ]
    }
   ],
   "source": [
    "# Charger et analyser le code depuis un fichier\n",
    "file_path = \"programme_mtddv.ts\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    code = file.read()\n",
    "\n",
    "parser = MTddVParser(code)\n",
    "parsed_structure = parser.parse()\n",
    "\n",
    "dot_output_path = \"./results/parsed_structure.dot\"\n",
    "png_output_path = \"./results/parsed_structure.png\"\n",
    "\n",
    "generate_dot(parsed_structure, dot_output_path)\n",
    "generate_png_from_dot(dot_output_path, png_output_path)\n",
    "\n",
    "output_filename = \"./results/parsed_structure.json\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(parsed_structure, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
